{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-03T18:52:12.838946440Z",
     "start_time": "2024-02-03T18:52:10.134648891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels torch.Size([229, 210])\n",
      "torch.Size([210, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wxy/anaconda3/envs/se31/lib/python3.11/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "predict torch.Size([229, 210])\n",
      "Epoch 1: Train Loss = 1.61359703540802\n",
      "Model saved to ./model_saves/final_antigen_model.pth\n",
      "Model saved to ./model_saves/final_antibody_model.pth\n",
      "Training completed and models saved.\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "predict torch.Size([229, 210])\n",
      "Epoch 2: Train Loss = 1.6095587015151978\n",
      "Model saved to ./model_saves/final_antigen_model.pth\n",
      "Model saved to ./model_saves/final_antibody_model.pth\n",
      "Training completed and models saved.\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "predict torch.Size([229, 210])\n",
      "Epoch 3: Train Loss = 1.605712652206421\n",
      "Model saved to ./model_saves/final_antigen_model.pth\n",
      "Model saved to ./model_saves/final_antibody_model.pth\n",
      "Training completed and models saved.\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "predict torch.Size([229, 210])\n",
      "Epoch 4: Train Loss = 1.6017717123031616\n",
      "Model saved to ./model_saves/final_antigen_model.pth\n",
      "Model saved to ./model_saves/final_antibody_model.pth\n",
      "Training completed and models saved.\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "predict torch.Size([229, 210])\n",
      "Epoch 5: Train Loss = 1.597590684890747\n",
      "Model saved to ./model_saves/final_antigen_model.pth\n",
      "Model saved to ./model_saves/final_antibody_model.pth\n",
      "Training completed and models saved.\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "predict torch.Size([229, 210])\n",
      "Epoch 6: Train Loss = 1.593157172203064\n",
      "Model saved to ./model_saves/final_antigen_model.pth\n",
      "Model saved to ./model_saves/final_antibody_model.pth\n",
      "Training completed and models saved.\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "predict torch.Size([229, 210])\n",
      "Epoch 7: Train Loss = 1.588618516921997\n",
      "Model saved to ./model_saves/final_antigen_model.pth\n",
      "Model saved to ./model_saves/final_antibody_model.pth\n",
      "Training completed and models saved.\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "predict torch.Size([229, 210])\n",
      "Epoch 8: Train Loss = 1.5839028358459473\n",
      "Model saved to ./model_saves/final_antigen_model.pth\n",
      "Model saved to ./model_saves/final_antibody_model.pth\n",
      "Training completed and models saved.\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "predict torch.Size([229, 210])\n",
      "Epoch 9: Train Loss = 1.5788342952728271\n",
      "Model saved to ./model_saves/final_antigen_model.pth\n",
      "Model saved to ./model_saves/final_antibody_model.pth\n",
      "Training completed and models saved.\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "torch.Size([210, 128])\n",
      "torch.Size([229, 128])\n",
      "predict torch.Size([229, 210])\n",
      "Epoch 10: Train Loss = 1.5735599994659424\n",
      "Model saved to ./model_saves/final_antigen_model.pth\n",
      "Model saved to ./model_saves/final_antibody_model.pth\n",
      "Training completed and models saved.\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Define a toy model: more complex models in experiments/qm9/models.py\n",
    "###\n",
    "#import dgl\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import umap\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.nn import Sequential as Seq, Dropout, GELU, Linear as Lin, ReLU, BatchNorm1d as BN, LayerNorm as LN, Softmax\n",
    "#from dgl import load_graphs\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.graphgym import optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from cross_attn import CrossAttention\n",
    "from sklearn import metrics\n",
    "from equivariant_attention.fibers import Fiber\n",
    "from equivariant_attention.modules import get_basis_and_r, GSE3Res, GNormSE3, GConvSE3, GMaxPooling\n",
    "from kfold import divide_5fold_bep3\n",
    "from zy_pytorchtools import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from Bio.PDB import PDBParser\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def extract_atom_coords(residue):\n",
    "    atom_coords = []\n",
    "    for atom in residue.get_atoms():\n",
    "        atom_coords.append(atom.get_coord())\n",
    "    return atom_coords\n",
    "\n",
    "def extract_amino_acids(pdb_file):\n",
    "    parser = PDBParser()\n",
    "    structure = parser.get_structure('protein', pdb_file)\n",
    "\n",
    "    amino_acids = []\n",
    "\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            for residue in chain:\n",
    "                if residue.get_resname().strip():  # Check if the residue has a name\n",
    "                    amino_acids.append(residue)\n",
    "\n",
    "    return amino_acids\n",
    "\n",
    "def calculate_min_distance_between_amino_acids(pdb_file1, pdb_file2):\n",
    "    amino_acids1 = extract_amino_acids(pdb_file1)\n",
    "    amino_acids2 = extract_amino_acids(pdb_file2)\n",
    "\n",
    "    num_amino_acids1 = len(amino_acids1)\n",
    "    num_amino_acids2 = len(amino_acids2)\n",
    "\n",
    "    min_distances_matrix = np.zeros((num_amino_acids1, num_amino_acids2))\n",
    "\n",
    "    for i, amino_acid1 in enumerate(amino_acids1):\n",
    "        coords1 = extract_atom_coords(amino_acid1)\n",
    "        for j, amino_acid2 in enumerate(amino_acids2):\n",
    "            coords2 = extract_atom_coords(amino_acid2)\n",
    "            distances = cdist(coords1, coords2)\n",
    "            min_distance = np.min(distances)\n",
    "            min_distances_matrix[i, j] = min_distance\n",
    "\n",
    "    return min_distances_matrix\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# The maximum feature type is harmonic degree 3\n",
    "\n",
    "num_degrees = 1\n",
    "num_features = 39  # 修改为实际的特征维度\n",
    "edge_dim = 78\n",
    "\n",
    "fiber_in = Fiber(1, num_features)  # 使用新的 num_features\n",
    "fiber_mid = Fiber(num_degrees, 32)  # 保持不变\n",
    "fiber_out = Fiber(1, 128)  # 保持不变\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.GSE3Res = GSE3Res(fiber_in, fiber_mid, edge_dim)\n",
    "        self.GNormSE3 = GNormSE3(fiber_mid)\n",
    "        self.GConvSE3 = GConvSE3(fiber_mid, fiber_out, edge_dim=edge_dim, self_interaction=True)\n",
    "        self.crossattention = CrossAttention(dim=128)\n",
    "        self.mlp_esm = Seq(Lin(128, 45), LN(45), GELU(), Lin(45, 1))\n",
    "        self.mlp_for_esm = Seq(Lin(1280, 128))\n",
    "        self.mlp_for_esm2 = Seq(Lin(1280, 2))\n",
    "        self.soft_max = Softmax(dim=1)\n",
    "\n",
    "    def bulid_se3(self):\n",
    "        se3 = nn.ModuleList([self.GSE3Res,\n",
    "                             self.GNormSE3,\n",
    "                             self.GConvSE3\n",
    "                             ])\n",
    "        return se3\n",
    "\n",
    "    def forward(self, data):\n",
    "        pool_batch = data.aa\n",
    "        if hasattr(data, 'edge_attr'):\n",
    "            edge_features = data.edge_attr\n",
    "            # 这里处理边的特征\n",
    "        else:\n",
    "            print(\"edge_attr not found in data object\")\n",
    "            # 可选的处理，如果边特征不存在\n",
    "\n",
    "        # 然后是其余的模型处理\n",
    "\n",
    "        G = data.G[0]\n",
    "        basis, r = get_basis_and_r(G, num_degrees - 1)\n",
    "        Se3Transformer = self.bulid_se3()\n",
    "        features = {'0': G.ndata['f']}\n",
    "\n",
    "        for layer in Se3Transformer:\n",
    "            features = layer(features, G=G, r=r, basis=basis)\n",
    "\n",
    "        # 在这里添加更多的打印语句来检查维度\n",
    "        out = features['0'][..., -1].unsqueeze(0)\n",
    "\n",
    "        out = global_mean_pool(out, pool_batch)\n",
    "\n",
    "        # 在每个线性层之前和之后添加打印语句\n",
    "        embedding = out\n",
    "        embedding = embedding.squeeze(0)\n",
    "        print(embedding.shape)\n",
    "        return embedding\n",
    "\n",
    "def embedding(model,anti):\n",
    "    model.train()\n",
    "    for data in anti:\n",
    "        data = data.to(device)\n",
    "        # 假设模型返回的是(out, embedding)，我们在这里打印out的形状\n",
    "        embedding = model(data)\n",
    "    # 返回最后一个out和embedding，注意这里我们返回的是一个元组\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def train_one_epoch_with_clip(antigen_model, antibody_model, labels,device, optimizer, criterion):\n",
    "    antigen_model.train()\n",
    "    antibody_model.train()\n",
    "    running_loss = 0.0\n",
    "    antigen_data = torch.load('./dataset/fea/11_2.pt', map_location=device)\n",
    "    antigen_loader = DataLoader([antigen_data], batch_size=1, shuffle=True, drop_last=True)\n",
    "    # 加载抗体数据\n",
    "    antibody_data = torch.load('./dataset/fea/11_1.pt', map_location=device)\n",
    "    antibody_loader = DataLoader([antibody_data], batch_size=1, shuffle=True, drop_last=True)\n",
    "    optimizer.zero_grad()\n",
    "    # 训练模型\n",
    "    antigen_features= embedding(antigen_model, antigen_loader)\n",
    "    antibody_features = embedding(antibody_model, antibody_loader)\n",
    "    antigen_features = torch.Tensor(antigen_features)\n",
    "    antibody_features= torch.Tensor(antibody_features)\n",
    "\n",
    "    print(antigen_features.shape)\n",
    "    print(antibody_features.shape)\n",
    "    antigen_features_normalized = antigen_features / torch.norm(antigen_features, dim=1, keepdim=True)\n",
    "    print(antigen_features_normalized.shape)\n",
    "    antibody_features_normalized = antibody_features / torch.norm(antibody_features, dim=1, keepdim=True)\n",
    "    print(antibody_features_normalized.shape)\n",
    "    antigen_features_normalized = antigen_features_normalized.transpose(0, 1)\n",
    "    predict = torch.mm(antibody_features_normalized, antigen_features_normalized)\n",
    "    print(\"predict\",predict.size())\n",
    "    labels = labels.to(device)\n",
    "    loss = criterion(predict,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss \n",
    "    return avg_loss\n",
    "\n",
    "def save_model(model, save_path, filename):\n",
    "    \"\"\"\n",
    "    保存模型的状态字典。\n",
    "    :param model: 要保存的模型。\n",
    "    :param save_path: 模型保存路径。\n",
    "    :param filename: 保存的文件名。\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    torch.save(model.state_dict(), os.path.join(save_path, filename))\n",
    "    print(f\"Model saved to {os.path.join(save_path, filename)}\")\n",
    "\n",
    "\n",
    "# 定义验证函数\n",
    "def validate_model(antigen_model, antibody_model, val_loader, device, criterion):\n",
    "    antigen_model.eval()\n",
    "    antibody_model.eval()\n",
    "    running_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            antigen_data, antibody_data, labels = batch\n",
    "            antigen_data, antibody_data, labels = antigen_data.to(device), antibody_data.to(device), labels.to(device)\n",
    "            antigen_features = antigen_model(antigen_data)\n",
    "            antibody_features = antibody_model(antibody_data)\n",
    "            # 计算损失...\n",
    "            val_loss = criterion(antigen_features, antibody_features, labels)\n",
    "            running_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = running_val_loss / len(val_loader)\n",
    "    return avg_val_loss\n",
    "\n",
    "# 示例使用\n",
    "save_path = './model_saves'\n",
    "num_epochs = 10\n",
    "\n",
    "def main():\n",
    "    # 两个PDB文件的路径\n",
    "    pdb_file1 = r'/home/wxy/Desktop/新建文件夹 1/se3/dataset/bep3/11/3MJ9_A.pdb'\n",
    "    pdb_file2 = r'/home/wxy/Desktop/新建文件夹 1/se3/dataset/bep3/11/3MJ9_H.pdb'\n",
    "\n",
    "    min_distances_matrix = calculate_min_distance_between_amino_acids(pdb_file1, pdb_file2)\n",
    "    min_distances_matrix = np.where(min_distances_matrix > 4.5, 0, 1)\n",
    "    min_distances_matrix = torch.Tensor(min_distances_matrix)\n",
    "    labels = min_distances_matrix\n",
    "    print(\"labels\",labels.size())\n",
    "    # 创建两个模型实例\n",
    "    antigen_model = Net().to(device)\n",
    "    antibody_model = Net().to(device)\n",
    "    # 优化器和损失函数\n",
    "    optimizer = optim.Adam(list(antigen_model.parameters()) + list(antibody_model.parameters()), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 训练和验证\n",
    "    save_path = './model_saves'\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_one_epoch_with_clip(antigen_model, antibody_model,labels, device, optimizer, criterion)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss}\")\n",
    "\n",
    "        # 训练完成后保存模型\n",
    "        save_model(antigen_model, save_path, 'final_antigen_model.pth')\n",
    "        save_model(antibody_model, save_path, 'final_antibody_model.pth')\n",
    "        print(\"Training completed and models saved.\")\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
