{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91a1be491b00f23d",
   "metadata": {},
   "source": [
    "### 导入一些包以及系统路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T08:56:20.074456200Z",
     "start_time": "2023-12-16T08:56:20.029598400Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "#### Local import\n",
    "import sys\n",
    "### 这样的操作通常用于解决模块导入的问题，特别是当你的代码和模块位于不同的目录中时\n",
    "sys.path.append('../../src')\n",
    "from utils.dataset import PDB_complex_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc64bab8ac423c",
   "metadata": {},
   "source": [
    "### 定义训练集和测试集并且定义一些常数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f84cd07ee9bc1ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T08:56:26.857305100Z",
     "start_time": "2023-12-16T08:56:26.836305600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/pycharm_project_560/training_example/data_preparation/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DIM=16\n",
    "\n",
    "DATA_DIR = os.getcwd()+'/data_preparation/'\n",
    "print(DATA_DIR)\n",
    "\n",
    "# 目前训练只采用训练集\n",
    "TRAIN_LIST_FILE = '../data/lists/training.txt'\n",
    "# VAL_LIST_FILE = '../data/lists/final_val.txt'\n",
    "\n",
    "PATIENCE=10 # number of consequitive times when model don't improve before early stopping\n",
    "SEED_ID = 7272\n",
    "BATCH_SIZE=1\n",
    "# 最大的训练次数\n",
    "MAX_EPOCH = 200\n",
    "\n",
    "# 加载piston的训练好的数据来最为我们模型训练的初始化参数\n",
    "MODEL_NAME=f'PIsToN_multiAttn_contrast'\n",
    "MODEL_DIR=f'./savedModels/{MODEL_NAME}'\n",
    "IMG_SIZE=32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246bb2dad2eb58d",
   "metadata": {},
   "source": [
    "### 定义config配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8705741577e81393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T08:38:28.506166Z",
     "start_time": "2023-12-16T08:38:28.483939600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/pycharm_project_560/training_example/data_preparation/07-grid\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "config = {}\n",
    "\n",
    "config['dirs'] = {}\n",
    "config['dirs']['data_prepare'] = DATA_DIR\n",
    "config['dirs']['grid'] = config['dirs']['data_prepare'] + '07-grid'\n",
    "config['dirs']['docked'] = config['dirs']['data_prepare'] + 'docked/'\n",
    "config['dirs']['tmp'] = '/aul/homes/vsteb002/tmp'\n",
    "\n",
    "config['ppi_const'] = {}\n",
    "config['ppi_const']['patch_r'] = 16 # 16\n",
    "\n",
    "os.environ[\"TMP\"] = config['dirs']['tmp']\n",
    "os.environ[\"TMPDIR\"] = config['dirs']['tmp']\n",
    "os.environ[\"TEMP\"] = config['dirs']['tmp']\n",
    "print(config['dirs']['grid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd08777ba5b15441",
   "metadata": {},
   "source": [
    "### 统计有多少复合物被处理了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e8eddd28035cb86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T08:58:42.104711500Z",
     "start_time": "2023-12-16T08:58:42.055522200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3L9R_A,2A6D_L', '5XMF_A,2A6J_A', '5XMM_A,2A6I_B', '4F7C_A,1FL6_C', '7EM9_A,4J1U_E', '7EMA_B,2A6K_A', '7EMB_B,2Z93_A', '7EMC_D,2Z91_A', '7XQU_E,1NLB_A', '6LF9_D,1QBM_B']\n",
      "0/10 training complexes were processed for 12A\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import get_processed\n",
    "# 目前阶段只采用训练集的数据\n",
    "train_list = [x.strip('\\n') for x in open(TRAIN_LIST_FILE, 'r').readlines()]\n",
    "print(train_list)\n",
    "# val_list = [x.strip('\\n') for x in open(VAL_LIST_FILE, 'r').readlines()]\n",
    "\n",
    "train_list_updated = get_processed(train_list, config)\n",
    "# val_list_updated = get_processed(val_list, config)\n",
    "\n",
    "print(f\"{len(train_list_updated)}/{len(train_list)} training complexes were processed for 12A\")\n",
    "# print(f\"{len(val_list_updated)}/{len(val_list)} validation complexes were processed for 12A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3cc124bc1b3161",
   "metadata": {},
   "source": [
    "### 学习图像标准缩放的平均值和标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46183d7c4979fd08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T08:59:18.729968900Z",
     "start_time": "2023-12-16T08:59:18.670448800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 antigen complexes \n",
      "Loaded 0 antibody complexes \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to stack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3616170/2323174407.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loaded {len(grid_antibody_list)} antibody complexes \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# n个抗原，每个抗原的形状是(n,32,32,7)，抗体同理\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mantigen_all_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_antigen_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mantibody_all_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_antibody_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mradius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ppi_const'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'patch_r'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/piston/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need at least one array to stack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to stack"
     ]
    }
   ],
   "source": [
    "## get all antigen and antibody lists\n",
    "grid_antigen_list = []\n",
    "grid_antibody_list = []\n",
    "for ppi in train_list:\n",
    "     antigen = ppi.split(',')[0]\n",
    "     antibody = ppi.split(',')[1]\n",
    "     antigen_grid_path = f\"{config['dirs']['grid']}/{antigen}.npy\"\n",
    "     antibody_grid_path = f\"{config['dirs']['grid']}/{antibody}.npy\"\n",
    "     if os.path.exists(antigen_grid_path ) and os.path.exists(antibody_grid_path):\n",
    "         grid_antigen_list.append(np.load(antigen_grid_path,allow_pickle=True))\n",
    "         grid_antibody_list.append(np.load(antibody_grid_path,allow_pickle=True))\n",
    "\n",
    "print(f\"Loaded {len(grid_antigen_list)} antigen complexes \")\n",
    "print(f\"Loaded {len(grid_antibody_list)} antibody complexes \")\n",
    "# n个抗原，每个抗原的形状是(n,32,32,7)，抗体同理\n",
    "antigen_all_grid = np.stack(grid_antigen_list,axis=0)\n",
    "antibody_all_grid = np.stack(grid_antibody_list,axis=0)\n",
    "radius = config['ppi_const']['patch_r']\n",
    "antigen_std_array = np.ones(7)\n",
    "antigen_mean_array = np.zeros(7)\n",
    "antibody_std_array = np.ones(7)\n",
    "antibody_mean_array = np.zeros(7)\n",
    "antigen_feature_pairs = {\n",
    "    'shape_index': (0,),\n",
    "    'ddc': (1,),\n",
    "    'electrostatics':(2,),\n",
    "    'charge': (3,),\n",
    "    'hydrophobicity': (4,),\n",
    "    'patch_dist':(5,),\n",
    "    'SASA': (6,)\n",
    "    }\n",
    "antibody_feature_pairs = {\n",
    "    'shape_index': (0,),\n",
    "    'ddc': (1,),\n",
    "    'electrostatics':(2,),\n",
    "    'charge': (3,),\n",
    "    'hydrophobicity': (4,),\n",
    "    'patch_dist':(5,),\n",
    "    'SASA': (6,)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9b5654e2317fa4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f71022a5d1ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute mean and std values of antigen \n",
    "for feature in antigen_feature_pairs.keys():\n",
    "    print(f\"Obtaining pixel values for {feature}\")\n",
    "    pixel_values = []\n",
    "    for feature_i in antigen_feature_pairs[feature]:\n",
    "        print(f\"Index {feature_i}\")\n",
    "        for image_i in tqdm(range(antigen_all_grid.shape[0])):\n",
    "            for row_i in range(antigen_all_grid.shape[1]):\n",
    "                for column_i in range(antigen_all_grid.shape[2]):\n",
    "                    # Check if coordinates are within the radius\n",
    "                    x = column_i - radius\n",
    "                    y = radius - row_i\n",
    "                    if x**2 + y**2 < radius**2:\n",
    "                        pixel_values.append(antigen_all_grid[image_i][row_i][column_i][feature_i])\n",
    "\n",
    "    antigen_mean_value = np.mean(pixel_values)\n",
    "    antigen_std_value = np.std(pixel_values)\n",
    "    print(f\"antigen  : Feature {feature}; Mean: {antigen_mean_value}; std: {antigen_std_value}\")\n",
    "    for feature_i in antigen_feature_pairs[feature]:\n",
    "        antigen_mean_array[feature_i] = antigen_mean_value\n",
    "        antigen_std_array[feature_i] = antigen_std_value\n",
    "    \n",
    "## compute mean and std values of antibody \n",
    "for feature in antibody_feature_pairs.keys():\n",
    "    print(f\"Obtaining pixel values for {feature}\")\n",
    "    pixel_values = []\n",
    "    for feature_i in antibody_feature_pairs[feature]:\n",
    "        print(f\"Index {feature_i}\")\n",
    "        for image_i in tqdm(range(antibody_all_grid.shape[0])):\n",
    "            for row_i in range(antibody_all_grid.shape[1]):\n",
    "                for column_i in range(antibody_all_grid.shape[2]):\n",
    "                    # Check if coordinates are within the radius\n",
    "                    x = column_i - radius\n",
    "                    y = radius - row_i\n",
    "                    if x**2 + y**2 < radius**2:\n",
    "                        pixel_values.append(antibody_all_grid[image_i][row_i][column_i][feature_i])\n",
    "\n",
    "    antibody_mean_value = np.mean(pixel_values)\n",
    "    antibody_std_value = np.std(pixel_values)\n",
    "    print(f\"antibody : Feature {feature}; Mean: {antibody_mean_value}; std: {antibody_std_value}\")\n",
    "    for feature_i in antigen_feature_pairs[feature]:\n",
    "        antibody_mean_array[feature_i] = antibody_mean_value\n",
    "        antibody_std_array[feature_i] = antibody_std_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd0b9e4871efd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Antigen Mean array:\")\n",
    "print(list(antigen_mean_array))\n",
    "print(\"\")\n",
    "print(\"Antigen Standard deviation array:\")\n",
    "print(list(antigen_std_array))\n",
    "print(\"Antibody Mean array:\")\n",
    "print(list(antibody_mean_array))\n",
    "print(\"\")\n",
    "print(\"Antibody Standard deviation array:\")\n",
    "print(list(antibody_std_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8982b61c9f1b9a13",
   "metadata": {},
   "source": [
    "## apply module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc16002c6a223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from networks.ViT_pytorch import Encoder\n",
    "from networks.ViT_hybrid import ViT_Hybrid_encoder\n",
    "\n",
    "class PISToN_proto(nn.Module):\n",
    "    \n",
    "    #定义模型，从父类方法中继承\n",
    "    def __init__(self,config,img_size=24,zero_head=False):\n",
    "        #构造调用模型的父类\n",
    "        super(PISToN_proto, self).__init__()\n",
    "        self.index_dict = {\n",
    "            'all features' : (0,1,2,3,4,5,6)\n",
    "        }\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.zero_head = zero_head\n",
    "        ### 创建一个ModuleList，将多个模块连接起来，方便管理\n",
    "        self.spatial_transformers_list = nn.ModuleList()\n",
    "        for feature in self.index_dict.keys():\n",
    "            self.spatial_transformers_list.append(self.init_transformer(config, channels=len(self.index_dict[feature])))\n",
    "        \n",
    "        self.feature_transformer = Encoder(config, vis=True) \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def init_transformer(self, config, channels, n_individual):\n",
    "        \"\"\"\n",
    "        Initialize Transformer Network for a given tupe of features\n",
    "        :param model_config:\n",
    "        :param channels:\n",
    "        :param n_individual:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return ViT_Hybrid_encoder(config, n_individual, img_size=self.img_size, channels=channels, vis=True)\n",
    "        \n",
    "    def forward(self,img,labels = None):\n",
    "        \n",
    "         all_x = []\n",
    "         all_spatial_attn = []\n",
    "         for i, feature in enumerate(self.index_dict.keys()):\n",
    "             # 从图片中得到我们所提取的特征\n",
    "             img_tmp = img[:,self.index_dict[feature],:,:]\n",
    "             x, attn = self.spatial_transformers_list[i](img_tmp)\n",
    "\n",
    "             all_x.append(x)\n",
    "             all_spatial_attn.append(attn)\n",
    "         \n",
    "         # 把所有的特征综合起来（其实这里只有一个，因为我们只有一组）\n",
    "         x = torch.stack(all_x, dim=1)\n",
    "         # 将所有的特征在经过过一个transformer encoder的编码\n",
    "         x, feature_attn = self.feature_transformer(x)\n",
    "         # 进行L2归一化，使向量在[-1,1]之间\n",
    "         x = nn.functional.normalize(x)\n",
    "         # 最后返回的是x，npy文件经过特征之后vit和transformer encoder得到的向量\n",
    "         return x, feature_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e6e71743e85618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.ViT_pytorch import get_ml_config\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_piston(search_space, train_list,SEED_ID, IMG_SIZE, \n",
    "                  antigen_std, antigen_mean, antibody_std, antibody_mean,\n",
    "                  MAX_EPOCHS=50, N_FEATURES=7,\n",
    "                  feature_subset=None,data_prepare_dir='./data_preparation/'):\n",
    "     assert len(antigen_mean) == N_FEATURES\n",
    "     if feature_subset is not None:\n",
    "        assert len(antigen_mean) == len(feature_subset)\n",
    "     ## 加载所有训练集的值\n",
    "     train_db = PDB_complex_training(train_list,\n",
    "                                  training_mode=True,\n",
    "                                  feature_subset=feature_subset,\n",
    "                                  data_prepare_dir=data_prepare_dir,\n",
    "                                  neg_pos_ratio=search_space['neg_pos_ratio'],\n",
    "                                  antigen_mean=antigen_mean,\n",
    "                                  antigen_std=antigen_std,\n",
    "                                  antibody_mean=antibody_mean, \n",
    "                                  antibody_std=antibody_std)\n",
    "     ##### Initialize data loaders\n",
    "     def worker_init_fn(worker_id):\n",
    "        random.seed(SEED_ID + worker_id)\n",
    "        \n",
    "     ###load the test data \n",
    "     trainloader = DataLoader(train_db, batch_size=1, shuffle=True, pin_memory=True)\n",
    "     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "     ##### Initailize model  search_space 是什么样的参数\n",
    "     ## 创建了一个模型的实例\n",
    "     model_config = get_ml_config(search_space)\n",
    "     model = PISToN_proto(model_config, img_size=IMG_SIZE).float()\n",
    "     optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "     for epoch in MAX_EPOCHS:\n",
    "         for data in trainloader:\n",
    "             antigen_grid, antibody_grid, ppi = data\n",
    "             antigen = antigen_grid.to(device=device, dtype=torch.float)\n",
    "             antibody = antibody_grid.to(device=device, dtype=torch.float)\n",
    "             antigen_output = model(antigen)\n",
    "             antibody_output = model(antibody)\n",
    "             antigen_vector, antigen_att = antigen_output\n",
    "             antibody_vector, antibody_att = antibody_output\n",
    "             print(antigen_vector.shape)\n",
    "             \n",
    "             ## 计算点乘结果，损失函数\n",
    "             dot_product = torch.dot(antigen_vector,antibody_vector)\n",
    "             target_dot_product = torch.tensor(1.0)\n",
    "             if dot_product < 1.0:\n",
    "                 loss = (1-dot_product)**2\n",
    "             else:\n",
    "                 loss = (dot_product-1)**2\n",
    "             \n",
    "             ## 梯度清零，反向传播，参数更新\n",
    "             optimizer.zero_grad()\n",
    "             loss.backward()\n",
    "             optimizer.step()\n",
    "         print(\"Epoch:\", epoch+1 , \"Loss:\", loss.item())\n",
    "         \n",
    "     \n",
    "     \n",
    "     \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0fd7e9629a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 定义模型的参数\n",
    "params = {'dim_head': DIM,\n",
    "          'hidden_size': DIM,\n",
    "          'dropout': 0,\n",
    "          'attn_dropout': 0,\n",
    "          'lr': 0.0001,\n",
    "          'n_heads': 8,\n",
    "          'neg_pos_ratio': 5,\n",
    "          'patch_size': 4,\n",
    "          'transformer_depth': 8,\n",
    "          'weight_decay': 0.0001,\n",
    "          }\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c0a6833d573afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 训练模型\n",
    "train_piston(params,train_list = train_list,SEED_ID=SEED_ID,IMG_SIZE=\n",
    "             IMG_SIZE,antigen_mean=antigen_mean_array,antigen_std=antigen_std_array,antibody_mean=antigen_mean_array,antibody_std=antigen_std_array,data_prepare_dir=DATA_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "piston",
   "language": "python",
   "name": "piston"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
